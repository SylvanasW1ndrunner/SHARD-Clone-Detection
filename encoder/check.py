# debug_pair.py

import pickle
import numpy as np
import networkx as nx
import pydot
import os

# --- ä¾èµ– ---
# ç¡®ä¿è¿™ä¸ªè„šæœ¬å¯ä»¥æ‰¾åˆ°å¹¶å¯¼å…¥æ‚¨çš„Vocabularyç±»
# å¦‚æœæ‚¨çš„ç±»åœ¨ä¸åŒæ–‡ä»¶ä¸­ï¼Œè¯·ç›¸åº”ä¿®æ”¹
from prepare_data import Vocabulary


def forensic_analysis(id1, id2, embeddings_cache_path, dot_dir_path):
    print(f"\n{'='*25}\næ³•è¯åˆ†æå¼€å§‹: {id1} vs {id2}\n{'='*25}")

    print("\n--- é˜¶æ®µä¸€: å¯¹æ¯”å·²ç¼“å­˜çš„â€œå—å‘é‡é›†åˆâ€ ---")
    if not os.path.exists(embeddings_cache_path):
        print(f"âŒ é”™è¯¯: ç¼–ç ç¼“å­˜æ–‡ä»¶ '{embeddings_cache_path}' ä¸å­˜åœ¨ã€‚")
        return

    with open(embeddings_cache_path, 'rb') as f:
        embeddings = pickle.load(f)

    vec_set1 = embeddings.get(id1)
    vec_set2 = embeddings.get(id2)

    if vec_set1 is None or vec_set2 is None:
        print(f"âŒ é”™è¯¯: åœ¨ç¼“å­˜ä¸­æ‰¾ä¸åˆ°åˆçº¦IDã€‚ID1: {'æ‰¾åˆ°' if vec_set1 is not None else 'æœªæ‰¾åˆ°'}, ID2: {'æ‰¾åˆ°' if vec_set2 is not None else 'æœªæ‰¾åˆ°'}")
        return

    print(f"  å‘é‡é›†1å½¢çŠ¶: {vec_set1.shape}, å‘é‡é›†2å½¢çŠ¶: {vec_set2.shape}")

    are_vectors_identical = False
    if vec_set1.shape == vec_set2.shape:
        sorted_vec1 = vec_set1[np.lexsort(vec_set1.T)]
        sorted_vec2 = vec_set2[np.lexsort(vec_set2.T)]
        diff = np.linalg.norm(sorted_vec1 - sorted_vec2)
        print(f"  æ’åºåå‘é‡é›†çš„å·®å¼‚ (L2èŒƒæ•°): {diff}")
        if diff < 1e-6:
            print("  âœ… ç»“è®º: ä¸¤ä¸ªå—å‘é‡é›†åˆåœ¨æ•°å€¼ä¸Šå®Œå…¨ç›¸åŒï¼")
            are_vectors_identical = True
        else:
            print("  âŒ ç»“è®º: ä¸¤ä¸ªå—å‘é‡é›†åˆåœ¨æ•°å€¼ä¸Šå­˜åœ¨å·®å¼‚ï¼è¿™æ˜¯å¯¼è‡´OTè·ç¦»ä¸ä¸º0çš„ç›´æ¥åŸå› ã€‚")
    else:
        print("  âŒ ç»“è®º: ä¸¤ä¸ªå—å‘é‡é›†åˆçš„å½¢çŠ¶ä¸åŒï¼è¿™æ˜¯å¯¼è‡´OTè·ç¦»ä¸ä¸º0çš„ç›´æ¥åŸå› ã€‚")

    if are_vectors_identical:
        print("\nğŸ”¥ è¯Šæ–­: å¦‚æœå‘é‡é›†ç›¸åŒä½†OTè·ç¦»ä»ä¸ä¸º0ï¼Œé—®é¢˜å¯èƒ½å‡ºåœ¨OTè®¡ç®—åº“çš„æ•°å€¼ç¨³å®šæ€§ä¸Šï¼Œä½†è¿™æå…¶ç½•è§ã€‚è¯·æ£€æŸ¥æ‚¨çš„OTè·ç¦»è®¡ç®—å‡½æ•°ã€‚")
        return

    # --- é˜¶æ®µäºŒï¼šå¦‚æœå‘é‡ä¸åŒï¼Œåˆ™æ·±å…¥å¯¹æ¯”æºDOTæ–‡ä»¶ ---
    print("\n--- é˜¶æ®µäºŒ: æ·±åº¦å¯¹æ¯”æº .dot æ–‡ä»¶å†…å®¹ ---")
    dot_path1 = os.path.join(dot_dir_path, f"{id1}_cfg.dot") # å‡è®¾æ–‡ä»¶åæ ¼å¼
    dot_path2 = os.path.join(dot_dir_path, f"{id2}_cfg.dot")

    if not (os.path.exists(dot_path1) and os.path.exists(dot_path2)):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°DOTæ–‡ä»¶ã€‚è·¯å¾„1: '{dot_path1}', è·¯å¾„2: '{dot_path2}'")
        return

    try:
        graph1 = nx.drawing.nx_pydot.from_pydot(pydot.graph_from_dot_file(dot_path1)[0])
        graph2 = nx.drawing.nx_pydot.from_pydot(pydot.graph_from_dot_file(dot_path2)[0])
    except Exception as e:
        print(f"åŠ è½½DOTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return
    edges1 = sorted([e for e in graph1.edges()])
    edges2 = sorted([e for e in graph2.edges()])
    print(f"  DOTæ–‡ä»¶1çš„è¾¹æ•°é‡: {len(edges1)}")
    print(f"  DOTæ–‡ä»¶2çš„è¾¹æ•°é‡: {len(edges2)}")
    nodes1 = sorted([n.strip('"') for n in graph1.nodes()])
    nodes2 = sorted([n.strip('"') for n in graph2.nodes()])
    print(f"  DOTæ–‡ä»¶1çš„èŠ‚ç‚¹æ•°é‡: {len(nodes1)}")
    print(f"  DOTæ–‡ä»¶2çš„èŠ‚ç‚¹æ•°é‡: {len(nodes2)}")
    if nodes1 != nodes2:
        print("âŒ è‡´å‘½å·®å¼‚: ä¸¤ä¸ªæ–‡ä»¶çš„èŠ‚ç‚¹åç§°åˆ—è¡¨ä¸åŒï¼")
        return

    print("  âœ… èŠ‚ç‚¹åç§°å’Œæ•°é‡ä¸€è‡´ã€‚å¼€å§‹é€ä¸€æ¯”å¯¹èŠ‚ç‚¹æ ‡ç­¾...")

    mismatch_found = False
    for node_name in nodes1:
        label1 = graph1.nodes[node_name].get('label', '').strip('"')
        label2 = graph2.nodes[node_name].get('label', '').strip('"')

        if label1 != label2:
            mismatch_found = True
            print(f"\n  âŒ å‘ç°æ ‡ç­¾ä¸åŒ¹é…ï¼èŠ‚ç‚¹: {node_name}")
            print("-" * 40)
            print(f"    æ–‡ä»¶1 (repr): {repr(label1)}")
            print(f"    æ–‡ä»¶2 (repr): {repr(label2)}")
            print("-" * 40)

    if not mismatch_found:
        print("  âœ… æ‰€æœ‰èŠ‚ç‚¹çš„æ ‡ç­¾åœ¨æ·±åº¦æ¯”å¯¹åå®Œå…¨ä¸€è‡´ã€‚")
        print("\nğŸ”¥ æœ€ç»ˆè¯Šæ–­: å¦‚æœèŠ‚ç‚¹æ ‡ç­¾å®Œå…¨ä¸€è‡´ï¼Œä½†ç¼–ç å‡ºçš„å‘é‡é›†ä¸åŒï¼ˆå¦‚é˜¶æ®µä¸€æ‰€ç¤ºï¼‰ï¼Œ")
        print("     è¿™å¼ºçƒˆæš—ç¤ºæ‚¨çš„ç¼–ç è¿‡ç¨‹å­˜åœ¨éšæœºæ€§ã€‚è¯·åŠ¡å¿…æ£€æŸ¥æ‚¨çš„encoderåŠ è½½åæ˜¯å¦è°ƒç”¨äº† `.eval()` æ¨¡å¼ï¼")
    else:
        print("\nğŸ”¥ æœ€ç»ˆè¯Šæ–­: å·²æ‰¾åˆ°æ ¹æœ¬åŸå› ï¼ä¸¤ä¸ªåˆçº¦çš„èŠ‚ç‚¹æ ‡ç­¾å†…å®¹å­˜åœ¨å¾®å°ä½†è‡´å‘½çš„å·®å¼‚ï¼Œå¯¼è‡´ç¼–ç ç»“æœä¸åŒã€‚")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == '__main__':
    # --- é…ç½® ---
    # è¯·å°†è¿™é‡Œçš„è·¯å¾„å’ŒIDä¿®æ”¹ä¸ºæ‚¨è¦è°ƒè¯•çš„ç›®æ ‡
    EMBEDDINGS_CACHE_PATH = 'embeddings.pkl'
    DOT_FILES_DIR = '../GNNdata/proccessed_cfg' # å­˜æ”¾.dotæ–‡ä»¶çš„æ–‡ä»¶å¤¹

    # æ‚¨å‘ç°é—®é¢˜çš„é‚£ä¸€å¯¹åˆçº¦ID
    CONTRACT_ID_1 = "0xd58a2e914f31c708442ff58871deb3a57c3322fc"
    CONTRACT_ID_2 = "0x506ce57a0050ffce5fe9437f606cb1d9db17a7b5"

    # --- è¿è¡Œåˆ†æ ---
    forensic_analysis(CONTRACT_ID_1, CONTRACT_ID_2, EMBEDDINGS_CACHE_PATH, DOT_FILES_DIR)